{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcd8b0f-2c53-485c-a232-cbe09ab5ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af612819-e9c5-4a32-a26c-3d2b8780bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data_breast_cancer['data'][['mean texture', 'mean symmetry']]\n",
    "y = data_breast_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33c7f9a-2995-4104-8337-77c008cee6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243f20e2-8023-448a-83c0-8aa963e8edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== DecisionTreeClassifier ==== \n",
      "train data: 1.0, \n",
      "test data: 0.6491228070175439\n",
      "\n",
      "==== LogisticRegression ==== \n",
      "train data: 0.7208791208791209, \n",
      "test data: 0.7105263157894737\n",
      "\n",
      "==== KNeighborsClassifier ==== \n",
      "train data: 0.7824175824175824, \n",
      "test data: 0.6754385964912281\n",
      "\n",
      "==== VotingClassifierHard ==== \n",
      "train data: 0.8571428571428571, \n",
      "test data: 0.7105263157894737\n",
      "\n",
      "==== VotingClassifierSoft ==== \n",
      "train data: 0.9714285714285714, \n",
      "test data: 0.6842105263157895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "reg_log = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('tc', tree_clf),\n",
    "                ('rl', reg_log), \n",
    "                ('kc', knn_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('tc', tree_clf),\n",
    "                ('rl', reg_log), \n",
    "                ('kc', knn_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "models = {\"DecisionTreeClassifier\" : tree_clf, \"LogisticRegression\" :  reg_log, \"KNeighborsClassifier\" :  knn_clf, \"VotingClassifierHard\" : voting_clf_hard, \"VotingClassifierSoft\" :  voting_clf_soft}\n",
    "acc_results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    acc_results.append((acc_train, acc_test))\n",
    "    print(f'==== {name} ==== \\ntrain data: {acc_train}, \\ntest data: {acc_test}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d7f58e-b23a-4b81-821c-6f3330fe63f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 0.6491228070175439), (0.7208791208791209, 0.7105263157894737), (0.7824175824175824, 0.6754385964912281), (0.8571428571428571, 0.7105263157894737), (0.9714285714285714, 0.6842105263157895)]\n",
      "[DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), VotingClassifier(estimators=[('tc', DecisionTreeClassifier()),\n",
      "                             ('rl', LogisticRegression()),\n",
      "                             ('kc', KNeighborsClassifier())]), VotingClassifier(estimators=[('tc', DecisionTreeClassifier()),\n",
      "                             ('rl', LogisticRegression()),\n",
      "                             ('kc', KNeighborsClassifier())],\n",
      "                 voting='soft')]\n"
     ]
    }
   ],
   "source": [
    "with open(\"acc_vote.pkl\", \"wb\") as f:\n",
    "    pickle.dump(acc_results, f)\n",
    "    \n",
    "with open(\"vote.pkl\", \"wb\") as f:\n",
    "    pickle.dump(list(models.values()), f)\n",
    "\n",
    "with open(\"acc_vote.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))\n",
    "    \n",
    "with open(\"vote.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd229b54-9d05-4471-8dc6-7a5ef208d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== BaggingClassifier ==== \n",
      "train data: 0.9956043956043956, \n",
      "test data: 0.6491228070175439\n",
      "\n",
      "==== BaggingClassifier_half_samples ==== \n",
      "train data: 0.9252747252747253, \n",
      "test data: 0.6929824561403509\n",
      "\n",
      "==== PastingClassifier ==== \n",
      "train data: 1.0, \n",
      "test data: 0.6578947368421053\n",
      "\n",
      "==== PastingClassifier_half_samples ==== \n",
      "train data: 0.9758241758241758, \n",
      "test data: 0.6929824561403509\n",
      "\n",
      "==== RandomForest ==== \n",
      "train data: 0.9978021978021978, \n",
      "test data: 0.6666666666666666\n",
      "\n",
      "==== AdaBoostClassifier ==== \n",
      "train data: 0.778021978021978, \n",
      "test data: 0.7105263157894737\n",
      "\n",
      "==== GradientBoostingClassifier ==== \n",
      "train data: 0.8373626373626374, \n",
      "test data: 0.7280701754385965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging and Pasting\n",
    "\n",
    "estimators_amount = 30\n",
    "base_clf = DecisionTreeClassifier()\n",
    "\n",
    "bag_clf = BaggingClassifier(base_clf, n_estimators=estimators_amount, bootstrap=True)\n",
    "bag_clf_half = BaggingClassifier(base_clf, n_estimators=estimators_amount, max_samples=0.5, bootstrap=True)\n",
    "past_clf = BaggingClassifier(base_clf, n_estimators=estimators_amount, bootstrap=False)\n",
    "past_clf_half = BaggingClassifier(base_clf, n_estimators=estimators_amount, max_samples=0.5, bootstrap=False)\n",
    "rnd_forest_clf = RandomForestClassifier(n_estimators=estimators_amount)\n",
    "adaboost = AdaBoostClassifier(n_estimators=estimators_amount)\n",
    "gradientboost = GradientBoostingClassifier(n_estimators=estimators_amount)\n",
    "\n",
    "models = {\"BaggingClassifier\" : bag_clf, \"BaggingClassifier_half_samples\" : bag_clf_half, \"PastingClassifier\" : past_clf, \"PastingClassifier_half_samples\" : past_clf_half, \n",
    "          \"RandomForest\" : rnd_forest_clf, \"AdaBoostClassifier\" : adaboost, \"GradientBoostingClassifier\" : gradientboost}\n",
    "acc_results_2 = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    acc_results_2.append((acc_train, acc_test))\n",
    "    print(f'==== {name} ==== \\ntrain data: {acc_train}, \\ntest data: {acc_test}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9ac03e-8365-42ac-b2ac-6923922891a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9956043956043956, 0.6491228070175439), (0.9252747252747253, 0.6929824561403509), (1.0, 0.6578947368421053), (0.9758241758241758, 0.6929824561403509), (0.9978021978021978, 0.6666666666666666), (0.778021978021978, 0.7105263157894737), (0.8373626373626374, 0.7280701754385965)]\n",
      "[BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=30), BaggingClassifier(estimator=DecisionTreeClassifier(), max_samples=0.5,\n",
      "                  n_estimators=30), BaggingClassifier(bootstrap=False, estimator=DecisionTreeClassifier(),\n",
      "                  n_estimators=30), BaggingClassifier(bootstrap=False, estimator=DecisionTreeClassifier(),\n",
      "                  max_samples=0.5, n_estimators=30), RandomForestClassifier(n_estimators=30), AdaBoostClassifier(n_estimators=30), GradientBoostingClassifier(n_estimators=30)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"acc_bag.pkl\", \"wb\") as f:\n",
    "    pickle.dump(acc_results_2, f)\n",
    "\n",
    "with open(\"bag.pkl\", \"wb\") as f:\n",
    "    pickle.dump(list(models.values()), f)\n",
    "\n",
    "with open(\"acc_bag.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))\n",
    "\n",
    "with open(\"bag.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e6545f-5dec-41e5-822d-8e4a5ae29ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== BaggingClassifierWithSampling ==== \n",
      "train data: 0.9956043956043956, \n",
      "test data: 0.9210526315789473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "\n",
    "X = data_breast_cancer['data']\n",
    "y = data_breast_cancer['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "fea_clf = BaggingClassifier(n_estimators=estimators_amount, bootstrap=True, max_features=2, bootstrap_features=False, max_samples=0.5)\n",
    "\n",
    "fea_clf.fit(X_train, y_train)\n",
    "y_pred_train = fea_clf.predict(X_train)\n",
    "y_pred_test = fea_clf.predict(X_test)\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "acc_results_3 = [acc_train, acc_test]\n",
    "print(f'==== BaggingClassifierWithSampling ==== \\ntrain data: {acc_train}, \\ntest data: {acc_test}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19f9586-74e0-4db8-9631-e61277dbf54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9956043956043956, 0.9210526315789473]\n",
      "[BaggingClassifier(max_features=2, max_samples=0.5, n_estimators=30)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"acc_fea.pkl\", \"wb\") as f:\n",
    "    pickle.dump(acc_results_3, f)\n",
    "\n",
    "with open(\"fea.pkl\", \"wb\") as f:\n",
    "    pickle.dump([fea_clf], f)\n",
    "\n",
    "with open(\"acc_fea.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))\n",
    "\n",
    "with open(\"fea.pkl\", \"rb\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0532db6c-e795-4ded-a7aa-175cf0147917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>[mean concavity, worst fractal dimension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>[worst concave points, worst symmetry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>[worst radius, worst area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>[worst smoothness, mean compactness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>[mean concavity, worst smoothness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>[worst fractal dimension, concave points error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[mean texture, mean area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[mean area, fractal dimension error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[concavity error, worst symmetry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[worst concave points, area error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[mean perimeter, texture error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[worst fractal dimension, worst radius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>[mean perimeter, mean concavity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>[fractal dimension error, symmetry error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>[worst radius, worst smoothness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>[mean fractal dimension, mean symmetry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>[mean fractal dimension, worst fractal dimension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>[mean concavity, worst concavity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>[worst radius, worst area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>[fractal dimension error, mean concave points]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>[compactness error, worst concave points]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>[worst fractal dimension, perimeter error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>[mean radius, mean concavity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>[perimeter error, mean smoothness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>[fractal dimension error, compactness error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>[compactness error, mean radius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>[texture error, mean perimeter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>[symmetry error, worst fractal dimension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>[concavity error, worst compactness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>[worst compactness, worst radius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc_train  acc_test                                           features\n",
       "9         1.0  0.964912          [mean concavity, worst fractal dimension]\n",
       "27        1.0  0.964912             [worst concave points, worst symmetry]\n",
       "16        1.0  0.956140                         [worst radius, worst area]\n",
       "18        1.0  0.956140               [worst smoothness, mean compactness]\n",
       "20        1.0  0.956140                 [mean concavity, worst smoothness]\n",
       "25        1.0  0.956140    [worst fractal dimension, concave points error]\n",
       "2         1.0  0.947368                          [mean texture, mean area]\n",
       "5         1.0  0.947368               [mean area, fractal dimension error]\n",
       "8         1.0  0.947368                  [concavity error, worst symmetry]\n",
       "15        1.0  0.947368                 [worst concave points, area error]\n",
       "22        1.0  0.947368                    [mean perimeter, texture error]\n",
       "23        1.0  0.947368            [worst fractal dimension, worst radius]\n",
       "29        1.0  0.947368                   [mean perimeter, mean concavity]\n",
       "6         1.0  0.938596          [fractal dimension error, symmetry error]\n",
       "17        1.0  0.938596                   [worst radius, worst smoothness]\n",
       "28        1.0  0.938596            [mean fractal dimension, mean symmetry]\n",
       "0         1.0  0.929825  [mean fractal dimension, worst fractal dimension]\n",
       "4         1.0  0.929825                  [mean concavity, worst concavity]\n",
       "19        1.0  0.929825                         [worst radius, worst area]\n",
       "26        1.0  0.929825     [fractal dimension error, mean concave points]\n",
       "1         1.0  0.921053          [compactness error, worst concave points]\n",
       "7         1.0  0.921053         [worst fractal dimension, perimeter error]\n",
       "12        1.0  0.921053                      [mean radius, mean concavity]\n",
       "21        1.0  0.921053                 [perimeter error, mean smoothness]\n",
       "10        1.0  0.912281       [fractal dimension error, compactness error]\n",
       "11        1.0  0.912281                   [compactness error, mean radius]\n",
       "14        1.0  0.912281                    [texture error, mean perimeter]\n",
       "24        1.0  0.912281          [symmetry error, worst fractal dimension]\n",
       "3         1.0  0.903509               [concavity error, worst compactness]\n",
       "13        1.0  0.903509                  [worst compactness, worst radius]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features Ranking\n",
    "\n",
    "estimators = fea_clf.estimators_\n",
    "estimators_features = fea_clf.estimators_features_\n",
    "acc_results_4 = []\n",
    "for clf, features in zip(estimators, estimators_features):\n",
    "    features_names = X.columns[features].to_list()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    acc_results_4.append((acc_train, acc_test, features_names))\n",
    "\n",
    "df = pd.DataFrame(acc_results_4, columns=[\"acc_train\", \"acc_test\", \"features\"])\n",
    "df = df.sort_values(by=[\"acc_test\", \"acc_train\"], ascending=False)\n",
    "\n",
    "with open(\"acc_fea_rank.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "with open(\"acc_fea_rank.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
